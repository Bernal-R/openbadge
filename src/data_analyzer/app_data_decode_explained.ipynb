{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw data file needs to be parsed line by line. Each line being a json format object.\n",
    "\n",
    "Raw data file structure:\n",
    "Line 1: \n",
    "        JSON object containing metadata for the meeting. For example:\n",
    "           \"uuid\":\"879EO_1464916044500\" # Unique identifier for meetings\n",
    "           \"group\":\"879EO\" # Unique identifier for groups\n",
    "           \"members\":[\"W6NMGEVHRE\",\"PVJPFRZB3S\"]\n",
    "           \"startTime\":\"2016-06-03T01:07:24.500Z\"\n",
    "           \"moderator\":\"none\"\n",
    "           \"location\":\"meetingroom\"\n",
    "           \"type\":\"study\"\n",
    "           \"description\":\"\"\n",
    "           \"showVisualization\":true\n",
    "\n",
    "Line 2 to EOF: \n",
    "        JSON object containing batched sample data and associated metadata. For example:\n",
    "            \"voltage\":2.7378299236297607\n",
    "            \"timestamp\":1464916052 # Reference UNIX timestamp for the start of the timeseries\n",
    "            \"timestamp_ms\":223 # Add to reference timestamp to get millisecond resolution\n",
    "            \"sampleDelay\":50 # Sampling period\n",
    "            \"numSamples\":114 # Number of samples in the \"samples\" array\n",
    "            \"samples\":[5,5,6,...] # Time series of volume\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First import the data from \"file_name\" as a JSON object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'timestamp': 1464916046, u'numSamples': 114, u'timestamp_ms': 523, u'voltage': 2.7378299236297607, u'samples': [6, 6, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 10, 5, 6, 5, 6, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 6, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 6, 5, 5, 6, 6, 5, 5, 6, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 5, 6, 5, 6, 6, 6, 5, 5, 5, 6, 6, 6, 6, 5, 6, 5, 5, 6, 5, 5, 5, 6, 5, 5], u'sampleDelay': 50}\n"
     ]
    }
   ],
   "source": [
    "input_file_name = \"879EO_1464916044500.txt\"\n",
    "with open(input_file_name,'r') as input_file:\n",
    "    raw_data = input_file.readlines() #This is a list of strings\n",
    "    meeting_metadata = json.loads(raw_data[0]) #Convert the header string into a json object\n",
    "    batched_sample_data = map(json.loads,raw_data[1:]) #Convert the raw sample data into a json object\n",
    "    print batched_sample_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to separate the individual samples from the batched samples. The following piece of code will create an array of individual samples while retaining the batch metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_data = []\n",
    "\n",
    "for j in range(len(batched_sample_data)):\n",
    "    batch = {}\n",
    "    batch.update(batched_sample_data[j]) #Create a deep copy of the jth batch of samples\n",
    "    samples = batch.pop('samples')\n",
    "    reference_timestamp = batch.pop('timestamp')*1000+batch.pop('timestamp_ms') #reference timestamp in milliseconds\n",
    "    sampleDelay = batch.pop('sampleDelay')\n",
    "    numSamples = batch.pop('numSamples')\n",
    "    for i in range(numSamples):\n",
    "        sample = {}\n",
    "        sample.update(batch)\n",
    "        sample['signal'] = samples[i]\n",
    "        sample['timestamp'] = reference_timestamp + i*sampleDelay\n",
    "        sample_data.append(sample)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a pandas dataframe from the list of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_sample_data = pd.DataFrame(sample_data)\n",
    "df_sample_data['datetime'] = pd.to_datetime(df_sample_data['timestamp'], unit='ms')\n",
    "del df_sample_data['timestamp']\n",
    "\n",
    "df_sample_data.sort_values('datetime')\n",
    "# Optional: Add the meeting metadata to the dataframe\n",
    "df_sample_data.metadata = meeting_metadata\n",
    "df_sample_data.set_index(pd.DatetimeIndex(df_sample_data['datetime']),inplace=True)\n",
    "df_sample_data.index.name = 'datetime'\n",
    "del df_sample_data['datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         signal   voltage\n",
      "datetime                                 \n",
      "2016-06-03 01:07:26.523       6  2.737830\n",
      "2016-06-03 01:07:26.573       6  2.737830\n",
      "2016-06-03 01:07:26.623       5  2.737830\n",
      "2016-06-03 01:07:26.673       6  2.737830\n",
      "2016-06-03 01:07:26.723       5  2.737830\n",
      "2016-06-03 01:07:26.773       5  2.737830\n",
      "2016-06-03 01:07:26.823       5  2.737830\n",
      "2016-06-03 01:07:26.873       5  2.737830\n",
      "2016-06-03 01:07:26.923       5  2.737830\n",
      "2016-06-03 01:07:26.973       5  2.737830\n",
      "2016-06-03 01:07:27.023       5  2.737830\n",
      "2016-06-03 01:07:27.073       5  2.737830\n",
      "2016-06-03 01:07:27.123       5  2.737830\n",
      "2016-06-03 01:07:27.173       5  2.737830\n",
      "2016-06-03 01:07:27.223       6  2.737830\n",
      "2016-06-03 01:07:27.273       5  2.737830\n",
      "2016-06-03 01:07:27.323       5  2.737830\n",
      "2016-06-03 01:07:27.373       5  2.737830\n",
      "2016-06-03 01:07:27.423       5  2.737830\n",
      "2016-06-03 01:07:27.473       5  2.737830\n",
      "2016-06-03 01:07:27.523       5  2.737830\n",
      "2016-06-03 01:07:27.573      10  2.737830\n",
      "2016-06-03 01:07:27.623       5  2.737830\n",
      "2016-06-03 01:07:27.673       6  2.737830\n",
      "2016-06-03 01:07:27.723       5  2.737830\n",
      "2016-06-03 01:07:27.773       6  2.737830\n",
      "2016-06-03 01:07:27.823       5  2.737830\n",
      "2016-06-03 01:07:27.873       5  2.737830\n",
      "2016-06-03 01:07:27.923       5  2.737830\n",
      "2016-06-03 01:07:27.973       5  2.737830\n",
      "...                         ...       ...\n",
      "2016-06-03 10:53:16.173       5  2.480938\n",
      "2016-06-03 10:53:16.223       5  2.480938\n",
      "2016-06-03 10:53:16.273       5  2.480938\n",
      "2016-06-03 10:53:16.323       5  2.480938\n",
      "2016-06-03 10:53:16.373       5  2.480938\n",
      "2016-06-03 10:53:16.423       5  2.480938\n",
      "2016-06-03 10:53:16.473       4  2.480938\n",
      "2016-06-03 10:53:16.523       4  2.480938\n",
      "2016-06-03 10:53:16.573       5  2.480938\n",
      "2016-06-03 10:53:16.623       5  2.480938\n",
      "2016-06-03 10:53:16.673       4  2.480938\n",
      "2016-06-03 10:53:16.723       4  2.480938\n",
      "2016-06-03 10:53:16.773       5  2.480938\n",
      "2016-06-03 10:53:16.823       4  2.480938\n",
      "2016-06-03 10:53:16.873       5  2.480938\n",
      "2016-06-03 10:53:16.923       5  2.480938\n",
      "2016-06-03 10:53:16.973       4  2.480938\n",
      "2016-06-03 10:53:17.023       4  2.480938\n",
      "2016-06-03 10:53:17.073       4  2.480938\n",
      "2016-06-03 10:53:17.123       4  2.480938\n",
      "2016-06-03 10:53:17.173       4  2.480938\n",
      "2016-06-03 10:53:17.223       4  2.480938\n",
      "2016-06-03 10:53:17.273       5  2.480938\n",
      "2016-06-03 10:53:17.323       5  2.480938\n",
      "2016-06-03 10:53:17.373       5  2.480938\n",
      "2016-06-03 10:53:17.423       5  2.480938\n",
      "2016-06-03 10:53:17.473       5  2.480938\n",
      "2016-06-03 10:53:17.523       5  2.480938\n",
      "2016-06-03 10:53:17.573       5  2.480938\n",
      "2016-06-03 10:53:17.623       4  2.480938\n",
      "\n",
      "[1405962 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print df_sample_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output the dataframe to a csv file if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "879EO_1464916044500.csv\n"
     ]
    }
   ],
   "source": [
    "output_file_name = input_file_name.split(\".\")[0] + \".csv\"\n",
    "print output_file_name\n",
    "df_sample_data.to_csv(output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
